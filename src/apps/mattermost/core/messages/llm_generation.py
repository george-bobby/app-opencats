"""Shared LLM generation utilities for messages."""

import datetime

from apps.mattermost.config.settings import settings
from apps.mattermost.models.message import ThreadForGeneration
from apps.mattermost.utils.ai import instructor_client
from apps.mattermost.utils.openai import get_system_prompt
from common.logger import logger


async def generate_thread_with_llm(
    user_prompt: str,
    context_type: str = "thread",
    temperature: float = 0.7,
) -> ThreadForGeneration | None:
    """
    Generate a thread using LLM with consistent error handling.

    Args:
        user_prompt: The prompt for the LLM
        context_type: Type of context for logging ("channel", "dm", "group_dm")
        temperature: LLM temperature setting

    Returns:
        ThreadForGeneration object or None if generation failed
    """
    try:
        response = await instructor_client.chat.completions.create(
            model=settings.DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": get_system_prompt()},
                {"role": "user", "content": user_prompt},
            ],
            response_model=ThreadForGeneration,
            temperature=temperature,
            max_tokens=settings.MAX_OUTPUT_TOKENS,
        )

        if not response or not response.messages:
            logger.warning(f"No {context_type} thread generated by LLM")
            return None

        return response

    except Exception as e:
        logger.error(f"Failed to generate {context_type} thread with LLM: {e}")
        return None


def create_user_directory_context(all_users: list[dict], limit: int = 20) -> str:
    """
    Create user directory context for LLM prompts.

    Args:
        all_users: List of user dictionaries
        limit: Maximum number of users to include

    Returns:
        Formatted user directory string
    """
    user_directory = []
    for user in all_users[:limit]:
        user_entry = f"ID {user['id']}: {user['username']} ({user.get('position', 'Unknown Position')})"
        user_directory.append(user_entry)

    return "\n        ".join(user_directory)


def create_timestamp_context(thread_start_time: int, context_label: str = "Thread") -> str:
    """
    Create timestamp context for LLM prompts.

    Args:
        thread_start_time: Timestamp in milliseconds
        context_label: Label for the context ("Thread", "Conversation", etc.)

    Returns:
        Formatted timestamp context string
    """
    start_date = datetime.datetime.fromtimestamp(thread_start_time / 1000)

    return f"""
        **{context_label} Timeline:**
        - This {context_label.lower()} started on {start_date.strftime("%B %d, %Y at %I:%M %p")}
        - Generate content that would be appropriate for that time period
    """


def create_attachment_instructions(should_have_attachments: bool) -> str:
    """
    Create attachment instructions for LLM prompts.

    Args:
        should_have_attachments: Whether this thread should include attachments

    Returns:
        Formatted attachment instruction string
    """
    if should_have_attachments:
        return """
        - **File Attachments**: This thread SHOULD include file attachments. Include relevant filenames naturally when sharing files. Examples:
          * "Here's the updated deployment config" → attachment_filenames: ["prod_deploy_config.yml"]
          * "Screenshot of the error I'm seeing" → attachment_filenames: ["database_error_screenshot.png"]
          * "Meeting notes and agenda from this morning" → attachment_filenames: ["standup_notes_jan15.md", "meeting_agenda.pdf"]"""
    else:
        return """
        - **File Attachments**: This thread should NOT include file attachments. Set attachment_filenames to empty list [] for all messages."""


def create_current_date_context() -> str:
    """
    Create current date context for LLM prompts.

    Returns:
        Formatted current date context string
    """
    current_time = datetime.datetime.now()
    current_date_str = current_time.strftime("%Y-%m-%d")

    return f"""
        **Current Time Context:**
        - Today's Date: {current_date_str}
        - Use this as your reference point for any time-sensitive content
    """


def create_markdown_guidelines(is_team_channel: bool = False) -> str:
    """
    Create markdown usage guidelines for LLM prompts.

    Args:
        is_team_channel: Whether this is for team channels (public/open) vs direct messages

    Returns:
        Formatted markdown guidelines string
    """
    if is_team_channel:
        return """
        **Message Guidelines for Team Channels:**
        - **Length**: Create varied message lengths with many longer, detailed messages (2-5 paragraphs)
        - **Natural Markdown Usage**: Use markdown selectively when it adds clarity or structure:
          * Use `code snippets` when referencing specific technical terms, file names, commands, or URLs
          * Use **bold** sparingly for emphasis on key points or important information
          * Use bullet points (-) or numbered lists (1.) when organizing multiple items or steps
          * Use ### headings occasionally to structure longer messages with multiple topics
          * Use ```code blocks``` when sharing actual code, configurations, or structured data
          * Use > blockquotes when referencing or quoting external sources
          * Don't force markdown formatting - use it naturally when it improves readability
          * Most formatting should be the natural flow of professional writing, not forced markdown
        """
    else:
        return """
        **Message Guidelines for Direct Messages:**
        - **Length**: Keep messages conversational and brief - mostly 1-2 sentences, occasional longer explanations
        - **Light Markdown Usage**: Use markdown sparingly for clarity:
          * Use `code snippets` for technical terms, file names, commands, or URLs
          * Use bullet points for quick lists (- option1, - option2)
          * Use **bold** for emphasis occasionally
          * Avoid formal headings or complex formatting - keep it conversational and flowing
        """


def create_business_theme_context() -> str:
    """
    Create business theme context for LLM prompts.

    Returns:
        Formatted business theme context string
    """
    return f"""
        Business Theme: {settings.DATA_THEME_SUBJECT}
    """
